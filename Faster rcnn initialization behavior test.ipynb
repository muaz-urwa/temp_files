{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
    "from torchvision.ops import misc as misc_nn_ops\n",
    "from torchvision.models import resnet\n",
    "from utils.utils import load_state_dict_from_url\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "model_urls = {\n",
    "    'fasterrcnn_resnet50_fpn_coco':\n",
    "        'https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_frozen_layers(model):\n",
    "    print(\"---- Frozen layers are: \")\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            print(name)\n",
    "    print(\"---------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torchvision Behavior\n",
    "- first conv and layer 1 block are frozen in all cases. Even if pretrained backbone and faster rcnn are not used, which is incorrect behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=False)\n",
    "\n",
    "show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
    "\n",
    "show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_fpn_backbone(backbone_name, pretrained, norm_layer=misc_nn_ops.FrozenBatchNorm2d, trainable_layers=3):\n",
    "    backbone = resnet.__dict__[backbone_name](\n",
    "        pretrained=pretrained,\n",
    "        norm_layer=norm_layer)\n",
    "    \"\"\"\n",
    "    Constructs a specified ResNet backbone with FPN on top of it. Freezes the specified number of layers in the backbone.\n",
    "    Examples::\n",
    "        >>> from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "        >>> backbone = resnet_fpn_backbone('resnet50', pretrained=True, trainable_layers=3)\n",
    "        >>> # get some dummy image\n",
    "        >>> x = torch.rand(1,3,64,64)\n",
    "        >>> # compute the output\n",
    "        >>> output = backbone(x)\n",
    "        >>> print([(k, v.shape) for k, v in output.items()])\n",
    "        >>> # returns\n",
    "        >>>   [('0', torch.Size([1, 256, 16, 16])),\n",
    "        >>>    ('1', torch.Size([1, 256, 8, 8])),\n",
    "        >>>    ('2', torch.Size([1, 256, 4, 4])),\n",
    "        >>>    ('3', torch.Size([1, 256, 2, 2])),\n",
    "        >>>    ('pool', torch.Size([1, 256, 1, 1]))]\n",
    "        \n",
    "    Arguments:\n",
    "        backbone_name (string): resnet architecture. Possible values are 'ResNet', 'resnet18', 'resnet34', 'resnet50',\n",
    "             'resnet101', 'resnet152', 'resnext50_32x4d', 'resnext101_32x8d', 'wide_resnet50_2', 'wide_resnet101_2'\n",
    "        norm_layer (torchvision.ops): it is recommended to use the default value. For details visit:\n",
    "            (https://github.com/facebookresearch/maskrcnn-benchmark/issues/267)\n",
    "        pretrained (bool): If True, returns a model with backbone pre-trained on Imagenet\n",
    "        trainable_layers (int): number of trainable (not frozen) resnet layers starting from final block.\n",
    "            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.\n",
    "    \"\"\"\n",
    "    # select layers that wont be frozen\n",
    "    assert trainable_layers<=5 and trainable_layers >=0\n",
    "    layers_to_train = ['layer4', 'layer3', 'layer2', 'layer1', 'conv1'][:trainable_layers]\n",
    "    # freeze layers only if pretrained backbone is used\n",
    "    for name, parameter in backbone.named_parameters():\n",
    "        if all([not name.startswith(layer) for layer in layers_to_train]):\n",
    "            parameter.requires_grad_(False)\n",
    "\n",
    "    return_layers = {'layer1': '0', 'layer2': '1', 'layer3': '2', 'layer4': '3'}\n",
    "\n",
    "    in_channels_stage2 = backbone.inplanes // 8\n",
    "    in_channels_list = [\n",
    "        in_channels_stage2,\n",
    "        in_channels_stage2 * 2,\n",
    "        in_channels_stage2 * 4,\n",
    "        in_channels_stage2 * 8,\n",
    "    ]\n",
    "    out_channels = 256\n",
    "    return BackboneWithFPN(backbone, return_layers, in_channels_list, out_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasterrcnn_resnet50_fpn(pretrained=False, progress=True,\n",
    "                            num_classes=91, pretrained_backbone=True, trainable_backbone_layers=3, **kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a Faster R-CNN model with a ResNet-50-FPN backbone.\n",
    "    The input to the model is expected to be a list of tensors, each of shape ``[C, H, W]``, one for each\n",
    "    image, and should be in ``0-1`` range. Different images can have different sizes.\n",
    "    The behavior of the model changes depending if it is in training or evaluation mode.\n",
    "    During training, the model expects both the input tensors, as well as a targets (list of dictionary),\n",
    "    containing:\n",
    "        - boxes (``FloatTensor[N, 4]``): the ground-truth boxes in ``[x1, y1, x2, y2]`` format, with values of ``x``\n",
    "          between ``0`` and ``W`` and values of ``y`` between ``0`` and ``H``\n",
    "        - labels (``Int64Tensor[N]``): the class label for each ground-truth box\n",
    "    The model returns a ``Dict[Tensor]`` during training, containing the classification and regression\n",
    "    losses for both the RPN and the R-CNN.\n",
    "    During inference, the model requires only the input tensors, and returns the post-processed\n",
    "    predictions as a ``List[Dict[Tensor]]``, one for each input image. The fields of the ``Dict`` are as\n",
    "    follows:\n",
    "        - boxes (``FloatTensor[N, 4]``): the predicted boxes in ``[x1, y1, x2, y2]`` format, with values of ``x``\n",
    "          between ``0`` and ``W`` and values of ``y`` between ``0`` and ``H``\n",
    "        - labels (``Int64Tensor[N]``): the predicted labels for each image\n",
    "        - scores (``Tensor[N]``): the scores or each prediction\n",
    "    Faster R-CNN is exportable to ONNX for a fixed batch size with inputs images of fixed size.\n",
    "    Example::\n",
    "        >>> model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "        >>> # For training\n",
    "        >>> images, boxes = torch.rand(4, 3, 600, 1200), torch.rand(4, 11, 4)\n",
    "        >>> labels = torch.randint(1, 91, (4, 11))\n",
    "        >>> images = list(image for image in images)\n",
    "        >>> targets = []\n",
    "        >>> for i in range(len(images)):\n",
    "        >>>     d = {}\n",
    "        >>>     d['boxes'] = boxes[i]\n",
    "        >>>     d['labels'] = labels[i]\n",
    "        >>>     targets.append(d)\n",
    "        >>> output = model(images, targets)\n",
    "        >>> # For inference\n",
    "        >>> model.eval()\n",
    "        >>> x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
    "        >>> predictions = model(x)\n",
    "        >>>\n",
    "        >>> # optionally, if you want to export the model to ONNX:\n",
    "        >>> torch.onnx.export(model, x, \"faster_rcnn.onnx\", opset_version = 11)\n",
    "    Arguments:\n",
    "        pretrained (bool): If True, returns a model pre-trained on COCO train2017\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "        pretrained_backbone (bool): If True, returns a model with backbone pre-trained on Imagenet\n",
    "        num_classes (int): number of output classes of the model (including the background)\n",
    "        trainable_backbone_layers (int): number of trainable (not frozen) resnet layers starting from final block.\n",
    "            Valid values are between 0 and 5, with 5 meaning all backbone layers are trainable.\n",
    "    \"\"\"\n",
    "    assert trainable_backbone_layers<=5 and trainable_backbone_layers >=0\n",
    "    # dont freeze any layers if pretrained model or backbone is not used\n",
    "    if not (pretrained or pretrained_backbone):\n",
    "        trainable_backbone_layers = 5\n",
    "    if pretrained:\n",
    "        # no need to download the backbone if pretrained is set\n",
    "        pretrained_backbone = False\n",
    "    backbone = resnet_fpn_backbone('resnet50', pretrained_backbone, trainable_layers=trainable_backbone_layers)\n",
    "    model = FasterRCNN(backbone, num_classes, **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls['fasterrcnn_resnet50_fpn_coco'],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When trainable_backbone_layers is not passed the behavior matches old behvaior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=True, progress=False,\n",
    "                            num_classes=91, pretrained_backbone=False)\n",
    "\n",
    "show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Old behavior is preserved except when both pretrained and pretrained_backbone are set to False. In that case no layers are frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Frozen layers are: \n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=False, progress=False,\n",
    "                            num_classes=91, pretrained_backbone=False)\n",
    "\n",
    "show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using trainable_backbone_layers to control the layers to freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================================\n",
      "--- 0 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "backbone.body.layer2.0.conv1.weight\n",
      "backbone.body.layer2.0.conv2.weight\n",
      "backbone.body.layer2.0.conv3.weight\n",
      "backbone.body.layer2.0.downsample.0.weight\n",
      "backbone.body.layer2.1.conv1.weight\n",
      "backbone.body.layer2.1.conv2.weight\n",
      "backbone.body.layer2.1.conv3.weight\n",
      "backbone.body.layer2.2.conv1.weight\n",
      "backbone.body.layer2.2.conv2.weight\n",
      "backbone.body.layer2.2.conv3.weight\n",
      "backbone.body.layer2.3.conv1.weight\n",
      "backbone.body.layer2.3.conv2.weight\n",
      "backbone.body.layer2.3.conv3.weight\n",
      "backbone.body.layer3.0.conv1.weight\n",
      "backbone.body.layer3.0.conv2.weight\n",
      "backbone.body.layer3.0.conv3.weight\n",
      "backbone.body.layer3.0.downsample.0.weight\n",
      "backbone.body.layer3.1.conv1.weight\n",
      "backbone.body.layer3.1.conv2.weight\n",
      "backbone.body.layer3.1.conv3.weight\n",
      "backbone.body.layer3.2.conv1.weight\n",
      "backbone.body.layer3.2.conv2.weight\n",
      "backbone.body.layer3.2.conv3.weight\n",
      "backbone.body.layer3.3.conv1.weight\n",
      "backbone.body.layer3.3.conv2.weight\n",
      "backbone.body.layer3.3.conv3.weight\n",
      "backbone.body.layer3.4.conv1.weight\n",
      "backbone.body.layer3.4.conv2.weight\n",
      "backbone.body.layer3.4.conv3.weight\n",
      "backbone.body.layer3.5.conv1.weight\n",
      "backbone.body.layer3.5.conv2.weight\n",
      "backbone.body.layer3.5.conv3.weight\n",
      "backbone.body.layer4.0.conv1.weight\n",
      "backbone.body.layer4.0.conv2.weight\n",
      "backbone.body.layer4.0.conv3.weight\n",
      "backbone.body.layer4.0.downsample.0.weight\n",
      "backbone.body.layer4.1.conv1.weight\n",
      "backbone.body.layer4.1.conv2.weight\n",
      "backbone.body.layer4.1.conv3.weight\n",
      "backbone.body.layer4.2.conv1.weight\n",
      "backbone.body.layer4.2.conv2.weight\n",
      "backbone.body.layer4.2.conv3.weight\n",
      "---------------------------\n",
      "===================================================\n",
      "--- 1 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "backbone.body.layer2.0.conv1.weight\n",
      "backbone.body.layer2.0.conv2.weight\n",
      "backbone.body.layer2.0.conv3.weight\n",
      "backbone.body.layer2.0.downsample.0.weight\n",
      "backbone.body.layer2.1.conv1.weight\n",
      "backbone.body.layer2.1.conv2.weight\n",
      "backbone.body.layer2.1.conv3.weight\n",
      "backbone.body.layer2.2.conv1.weight\n",
      "backbone.body.layer2.2.conv2.weight\n",
      "backbone.body.layer2.2.conv3.weight\n",
      "backbone.body.layer2.3.conv1.weight\n",
      "backbone.body.layer2.3.conv2.weight\n",
      "backbone.body.layer2.3.conv3.weight\n",
      "backbone.body.layer3.0.conv1.weight\n",
      "backbone.body.layer3.0.conv2.weight\n",
      "backbone.body.layer3.0.conv3.weight\n",
      "backbone.body.layer3.0.downsample.0.weight\n",
      "backbone.body.layer3.1.conv1.weight\n",
      "backbone.body.layer3.1.conv2.weight\n",
      "backbone.body.layer3.1.conv3.weight\n",
      "backbone.body.layer3.2.conv1.weight\n",
      "backbone.body.layer3.2.conv2.weight\n",
      "backbone.body.layer3.2.conv3.weight\n",
      "backbone.body.layer3.3.conv1.weight\n",
      "backbone.body.layer3.3.conv2.weight\n",
      "backbone.body.layer3.3.conv3.weight\n",
      "backbone.body.layer3.4.conv1.weight\n",
      "backbone.body.layer3.4.conv2.weight\n",
      "backbone.body.layer3.4.conv3.weight\n",
      "backbone.body.layer3.5.conv1.weight\n",
      "backbone.body.layer3.5.conv2.weight\n",
      "backbone.body.layer3.5.conv3.weight\n",
      "---------------------------\n",
      "===================================================\n",
      "--- 2 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "backbone.body.layer2.0.conv1.weight\n",
      "backbone.body.layer2.0.conv2.weight\n",
      "backbone.body.layer2.0.conv3.weight\n",
      "backbone.body.layer2.0.downsample.0.weight\n",
      "backbone.body.layer2.1.conv1.weight\n",
      "backbone.body.layer2.1.conv2.weight\n",
      "backbone.body.layer2.1.conv3.weight\n",
      "backbone.body.layer2.2.conv1.weight\n",
      "backbone.body.layer2.2.conv2.weight\n",
      "backbone.body.layer2.2.conv3.weight\n",
      "backbone.body.layer2.3.conv1.weight\n",
      "backbone.body.layer2.3.conv2.weight\n",
      "backbone.body.layer2.3.conv3.weight\n",
      "---------------------------\n",
      "===================================================\n",
      "--- 3 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "backbone.body.layer1.0.conv1.weight\n",
      "backbone.body.layer1.0.conv2.weight\n",
      "backbone.body.layer1.0.conv3.weight\n",
      "backbone.body.layer1.0.downsample.0.weight\n",
      "backbone.body.layer1.1.conv1.weight\n",
      "backbone.body.layer1.1.conv2.weight\n",
      "backbone.body.layer1.1.conv3.weight\n",
      "backbone.body.layer1.2.conv1.weight\n",
      "backbone.body.layer1.2.conv2.weight\n",
      "backbone.body.layer1.2.conv3.weight\n",
      "---------------------------\n",
      "===================================================\n",
      "--- 4 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "backbone.body.conv1.weight\n",
      "---------------------------\n",
      "===================================================\n",
      "--- 5 trainable layers  -----\n",
      "---- Frozen layers are: \n",
      "---------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):\n",
    "    print('===================================================')\n",
    "    print('--- '+str(i)+' trainable layers  -----')\n",
    "    \n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=True, progress=False,\n",
    "                                num_classes=91, pretrained_backbone=False, trainable_backbone_layers=i)\n",
    "\n",
    "    show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- checking for invalid trainable_backbone_layers value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-56acfa978810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model = fasterrcnn_resnet50_fpn(pretrained=False, progress=False,\n\u001b[0;32m----> 2\u001b[0;31m                             num_classes=91, pretrained_backbone=False, trainable_backbone_layers=7)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshow_frozen_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-68e599b9c1d9>\u001b[0m in \u001b[0;36mfasterrcnn_resnet50_fpn\u001b[0;34m(pretrained, progress, num_classes, pretrained_backbone, trainable_backbone_layers, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mValid\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0mmeaning\u001b[0m \u001b[0mall\u001b[0m \u001b[0mbackbone\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0mare\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtrainable_backbone_layers\u001b[0m\u001b[0;34m<=\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtrainable_backbone_layers\u001b[0m \u001b[0;34m>=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;31m# dont freeze any layers if pretrained model or backbone is not used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpretrained_backbone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = fasterrcnn_resnet50_fpn(pretrained=False, progress=False,\n",
    "                            num_classes=91, pretrained_backbone=False, trainable_backbone_layers=7)\n",
    "\n",
    "show_frozen_layers(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
